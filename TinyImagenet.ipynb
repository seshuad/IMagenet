{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiny Imagenet Visual Recognition Challenge\n",
    "\n",
    "Tiny Imagenet has 200 Classes, each class has 500 traininig images, 50 Validation Images and 50 test images. Label Classes and Bounding Boxes are provided. More details can be found at https://tiny-imagenet.herokuapp.com/\n",
    "\n",
    "This challenge is part of Stanford Class CS 213N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import requests, StringIO\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_CLASSES = 200\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "NUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\n",
    "TRAINING_IMAGES_DIR = './tiny-imagenet-200/train/'\n",
    "TRAIN_SIZE = NUM_IMAGES\n",
    "\n",
    "NUM_VAL_IMAGES = 10000\n",
    "VAL_IMAGES_DIR = './tiny-imagenet-200/val/'\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "NUM_CHANNELS = 3\n",
    "IMAGE_ARR_SIZE = IMAGE_SIZE * IMAGE_SIZE * NUM_CHANNELS\n",
    "IMAGES_URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "\n",
    "def download_images(url):\n",
    "    if (os.path.isdir(TRAINING_IMAGES_DIR)):\n",
    "        print ('Images already downloaded...')\n",
    "        return\n",
    "    r = requests.get(url, stream=True)\n",
    "    print ('Downloading ' + url )\n",
    "    zip_ref = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
    "    zip_ref.extractall('./')\n",
    "    zip_ref.close()\n",
    "\n",
    "def load_training_images(image_dir, batch_size=500):\n",
    "\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(NUM_IMAGES, IMAGE_ARR_SIZE))\n",
    "    names = np.chararray(shape=(NUM_IMAGES))\n",
    "    labels = np.chararray(shape=(NUM_IMAGES))                        \n",
    "    \n",
    "    # Loop through all the types directories\n",
    "    for type in os.listdir(image_dir):\n",
    "        if os.path.isdir(image_dir + type + '/images/'):\n",
    "            type_images = os.listdir(image_dir + type + '/images/')\n",
    "            # Loop through all the images of a type directory\n",
    "            batch_index = 0;\n",
    "            print (\"Loading Class \", type)\n",
    "            for image in type_images:\n",
    "                image_file = os.path.join(image_dir, type + '/images/', image)\n",
    "\n",
    "                # reading the images as they are; no normalization, no color editing\n",
    "                image_data = mpimg.imread(image_file) \n",
    "                #print ('Loaded Image', image_file, image_data.shape)\n",
    "                if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "                    images[image_index, :] = image_data.flatten()\n",
    "\n",
    "                    labels[image_index] = type\n",
    "                    names[image_index] = image\n",
    "                    \n",
    "                    image_index += 1\n",
    "                    batch_index += 1\n",
    "                if (batch_index >= batch_size):\n",
    "                    break;\n",
    "                    \n",
    "    return (images, labels, names)\n",
    "\n",
    "def get_label_from_name(data, name):\n",
    "    for idx, row in data.iterrows():\n",
    "        \n",
    "        if (row['File'] == name):\n",
    "            return row['Class']\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_validation_images(testdir, validation_data, batch_size=NUM_VAL_IMAGES):\n",
    "    labels = []\n",
    "    names = []\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(batch_size, IMAGE_ARR_SIZE))\n",
    "    val_images = os.listdir(testdir + '/images/')\n",
    "           \n",
    "    # Loop through all the images of a val directory\n",
    "    batch_index = 0;\n",
    "    \n",
    "    \n",
    "    for image in val_images:\n",
    "        image_file = os.path.join(testdir, 'images/', image)\n",
    "        #print (testdir, image_file)\n",
    "\n",
    "        # reading the images as they are; no normalization, no color editing\n",
    "        image_data = mpimg.imread(image_file) \n",
    "        if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "            images[image_index, :] = image_data.flatten()\n",
    "            image_index += 1\n",
    "            labels.append(get_label_from_name(validation_data, image))\n",
    "            names.append(image)\n",
    "            batch_index += 1\n",
    "            \n",
    "        if (batch_index >= batch_size):\n",
    "            break;\n",
    "    \n",
    "    print (\"Loaded Validation images \", image_index)\n",
    "    return (images, np.asarray(labels), np.asarray(names))\n",
    "   \n",
    "    \n",
    "\n",
    "def plot_object(data):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    image = data.reshape(IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_objects(instances, images_per_row=10, **options):\n",
    "    size = IMAGE_SIZE\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size,NUM_CHANNELS) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        if (row == len(instances)/images_per_row):\n",
    "            break\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, **options)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_next_batch(batchsize=50):\n",
    "    for cursor in range(0, len(training_images), batchsize):\n",
    "        batch = []\n",
    "        batch.append(training_images[cursor:cursor+batchsize])\n",
    "        batch.append(training_labels_encoded[cursor:cursor+batchsize])       \n",
    "        yield batch\n",
    "\n",
    "def get_next_labels(batchsize=50):\n",
    "    for cursor in range(0, len(training_images), batchsize):\n",
    "        yield training_labels_encoded[cursor:cursor+batchsize]  \n",
    "    \n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height = IMAGE_SIZE\n",
    "width = IMAGE_SIZE\n",
    "channels = NUM_CHANNELS\n",
    "n_inputs = height * width * channels\n",
    "\n",
    "n_outputs = 200\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "#input shape [-1, 64, 64, 3]\n",
    "conv1 = tf.layers.conv2d(\n",
    "            inputs=X_reshaped, \n",
    "            filters=32, \n",
    "            kernel_size=[5,5],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu, \n",
    "            name=\"conv1\")\n",
    "\n",
    "#shape after conv1: [-1, 64, 64, 32]\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1, \n",
    "            filters=64,\n",
    "            kernel_size=[5,5],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu, \n",
    "            name=\"conv2\")\n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Dense Layer\n",
    "pool2_flat = tf.reshape(pool2, [-1, 8 * 8 * 64])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=0.4)\n",
    "dropout_reshape = tf.reshape(dropout, [-1, 8 * 8 * 64])\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dropout_reshape, units=200, name='output')\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images already downloaded...\n",
      "('Loading Class ', 'n01443537')\n",
      "('Loading Class ', 'n01629819')\n",
      "('Loading Class ', 'n01641577')\n",
      "('Loading Class ', 'n01644900')\n",
      "('Loading Class ', 'n01698640')\n",
      "('Loading Class ', 'n01742172')\n",
      "('Loading Class ', 'n01768244')\n",
      "('Loading Class ', 'n01770393')\n",
      "('Loading Class ', 'n01774384')\n",
      "('Loading Class ', 'n01774750')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-93df573546e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdownload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGES_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_training_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_IMAGES_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_labels_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-de4c6c543329>\u001b[0m in \u001b[0;36mload_training_images\u001b[0;34m(image_dir, batch_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# reading the images as they are; no normalization, no color editing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;31m#print ('Loaded Image', image_file, image_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "download_images(IMAGES_URL)\n",
    "training_images, training_labels, training_files = load_training_images(TRAINING_IMAGES_DIR)\n",
    "le = preprocessing.LabelEncoder()\n",
    "training_le = le.fit(training_labels)\n",
    "training_labels_encoded = training_le.transform(training_labels)\n",
    "\n",
    "shuffle_index = np.random.permutation(NUM_IMAGES)\n",
    "training_images = training_images[shuffle_index]\n",
    "training_labels = training_labels[shuffle_index]\n",
    "training_files  = training_files[shuffle_index]\n",
    "training_labels_encoded = training_labels_encoded[shuffle_index]\n",
    "\n",
    "\n",
    "plot_objects(training_images[0:30])\n",
    "print (training_labels_encoded[0:30])\n",
    "\n",
    "val_data = pd.read_csv(VAL_IMAGES_DIR + 'val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "val_images, val_labels, val_files = load_validation_images(VAL_IMAGES_DIR, val_data, batch_size=BATCH_SIZE)\n",
    "val_labels_encoded = training_le.transform(val_labels)\n",
    "plot_objects(val_images[0:30])\n",
    "print (val_labels_encoded[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in get_next_batch():\n",
    "            X_batch, y_batch = batch[0], batch[1]\n",
    "            print ('Training set', y_batch)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "       \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: val_images, y: val_labels_encoded})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "        save_path = saver.save(sess, \"./tiny_imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
